---
title: NYC's Criminal Summers
subtitle: This is a quick look at crime in NYC.
output: 
  prettydoc::html_pretty:
    theme: tactile
---
#### Built in R 4.0.2
# Executive Summary

Domain expert want to understand major trends and insights about NYC crime/violence from several public data source to enable the police officers on patrol. This report analyzes and looks for trends that "beat officers" can use in their daily operations. 

The output of this is a model that police officers can use to predict crime in each of their five Boros based on the date and weather. Crime picks a seasonal pattern and weather plays a factor. With client iteration, this tool could be invaluable in managing scarce police department resources.  

Please visit the follow site to see the minimum viable product. https://oldhero5.shinyapps.io/nyc_crime/ 

Additionally, the repo is available @ https://github.com/oldhero5/nyc_crime


```{r, echo = FALSE, warning=FALSE}
#load libraries

library(tidyverse)
library(leaflet)

#adjust options 
options(scipen = 666) # remove scientific numbers
```

```{r, warning=FALSE}
# Read Data from internet

# df_arrests_hist <-read_csv("https://data.cityofnewyork.us/api/views/8h9b-rp9u/rows.csv?accessType=DOWNLOAD")%>%
#   janitor::clean_names()

df_arrests_hist <-read_csv("df_arrests_hist.csv")%>%
  janitor::clean_names()


df_arrests_ytd <- read_csv("https://data.cityofnewyork.us/api/views/uip8-fykc/rows.csv?accessType=DOWNLOAD")%>%
  janitor::clean_names()

df_shooting <- read_csv("https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD") %>% 
  janitor::clean_names()

```

#### Exploratory Data Analysis

 Let's begin exploring the data to see any initial insights. 

```{r echo = T}

glimpse(df_arrests_hist)

```
```{r}
glimpse(df_arrests_ytd)

```

```{r}
glimpse(df_shooting)

```

Let's build a dataset that combines all the arrest data into one while removing duplicates from where they overlap.

```{r}
df_arrests <- df_arrests_hist %>% 
  bind_rows(df_arrests_ytd)%>%
  distinct() %>% 
  drop_na(ofns_desc)
glimpse(df_arrests)
```

```{r}
df <- df_arrests %>% 
  rename(incident_key=arrest_key) %>%
  rename(occur_date = arrest_date) %>% 
  bind_rows(df_shooting)
glimpse(df)
```
I'm going to first look at arrest data and see what types of categories exist. I have a feeling that some types of crimes are more frequent than others.

```{r}
df%>% 
  count(ofns_desc,sort = T)
  
```

Drug offenses seem to be the most frequent historical occurrence within the data. I wonder how that frequency changes with time. Let’s take a look at what the day averages look like each year. 
It seems that arrests for dangerous drugs are on a decline.

```{r}
df %>%
    filter(ofns_desc == "DANGEROUS DRUGS") %>% 
  mutate(
    occur_date = lubridate::mdy(occur_date),
         year = lubridate::year(occur_date),
         year = factor(year),
         month = lubridate:: month(occur_date),
         month = factor(month))%>%
  group_by(occur_date)%>%
  mutate(
    count_daily = n())%>%
  ungroup()%>%
  ggplot(aes(factor(year), count_daily,
    fill = year, color = year
  )) +
  geom_boxplot(alpha = 0.2, size = 1, show.legend = FALSE) +
  labs(x = NULL, y = "Daily Drug Arrests")

```

Perhaps in era of shrinking police budgets, it would be useful to target police officer scheduling to have more police scheduled to be in generally correct locations at the right times to discourage nefarious activities and increase public safety. While Daily Drug arrests might be interesting, they may not be a large danger to society. However, violent crime may be. First, I’ll label data to find violent crime. For this we will need to clean some of the data. Let’s look at the second most common crime assault. In this exploratory data section, I'll use this as a proxy for overall violent crimes to determine a good time frame to use for predictions.

```{r}

# The palette with grey:
df %>%
    filter(ofns_desc == "ASSAULT 3 & RELATED OFFENSES") %>% 
  mutate(
    occur_date = lubridate::mdy(occur_date),
         year = lubridate::year(occur_date),
         year = factor(year),
         month = lubridate:: month(occur_date),
         month = factor(month))%>%
  group_by(occur_date)%>%
  mutate(
    count_daily = n())%>%
  ungroup()%>%
  ggplot(aes(year, count_daily,
    fill = year, color = year, group =year)) + 
  geom_boxplot(alpha = 0.2, size = 1, show.legend = FALSE)+
  labs(x = NULL, y = "Daily Assault Arrests")
```

It appears that a large reduction in "ASSAULT 3 & RELATED OFFENSES," occurs around 2015. I'll assume this is the modern era of policing and use only data from 2015 on. 

```{r}
df1 <- df %>%
   mutate(
     occur_date = lubridate::mdy(occur_date),
         year = lubridate::year(occur_date),
         month = lubridate:: month(occur_date),
         year_mon = zoo::as.yearmon(occur_date, "%m/%Y"))%>% 
  filter(year >=2015) %>%
  mutate(
    ofns_desc=ifelse(is.na(ofns_desc),"shooting",ofns_desc),
         statistical_murder_flag= ifelse(is.na(statistical_murder_flag), FALSE, statistical_murder_flag),
        occur_date = lubridate::as_date(occur_date),
        occur_time = ifelse(is.na(occur_time),12:00,occur_time),
        incident_key = ifelse(is.na(incident_key),arrest_key,incident_key),
        precinct = ifelse(is.na(precinct),arrest_precinct,precinct),
        boro = ifelse(is.na(boro),arrest_boro,boro),
        boro = ifelse(boro=="M","MANHATTAN",
                      ifelse(boro=="K", "BROOKLYN",
                             ifelse(boro=="S", "STATEN ISLAND",
                                    ifelse(boro=="B", "BRONX",
                                           ifelse(boro=="Q","QUEENS",boro)))))) %>%
  select(-vic_race,-vic_sex,-vic_age_group,-perp_age_group,-location_desc,
         -arrest_boro,-new_georeferenced_column)
  
  glimpse(df1)
```

First, I would like to see how many crime categories there are and simplify a way to bin them. My going assumption is to focus on violent crimes, thefts or damage to property, and petty crimes. We will see what the data yields.

```{r}
df1 %>% 
  select(ofns_desc) %>% 
  n_distinct()
```
Eighty-three crime categories are a lot. I think binning could reduce this dimensionality. In this case, I plan to bin by violent crimes, theft or property crimes, and other crimes.

```{r}
df1 <- df1 %>% 
  mutate(
    crime_type = case_when(
      str_detect(ofns_desc, "ASSAULT")~"violent",
      str_detect(ofns_desc, "shooting")~"violent",
      str_detect(ofns_desc, "HOMICIDE")~"violent",
      str_detect(ofns_desc, "MURDER")~"violent",
      str_detect(ofns_desc, "RAPE")~"violent",
      str_detect(ofns_desc, "FORC")~"violent",
      str_detect(ofns_desc, "SEX")~"violent",
      str_detect(ofns_desc, "KID")~"violent",
      str_detect(ofns_desc, "WEAP")~"violent",
      str_detect(ofns_desc, "DANG")~"violent",
      str_detect(ofns_desc, "HARASSMENT")~"violent",
      str_detect(ofns_desc, "THEFT")~"theft_property",
      str_detect(ofns_desc, "LARCENY")~"theft_property",
      str_detect(ofns_desc, "ARSON")~"theft_property",
      str_detect(ofns_desc, "ENTRY")~"theft_property",
      str_detect(ofns_desc, "FRAUD")~"theft_property",
      str_detect(ofns_desc, "VEHICLE")~"theft_property",
      str_detect(ofns_desc, "ROBBERY")~"theft_property",
      str_detect(ofns_desc, "BURGLAR")~"theft_property",
      str_detect(ofns_desc, "FORG")~"theft_property",
      str_detect(ofns_desc, "PROP")~"theft_property",
      str_detect(ofns_desc, "PARK")~"theft_property",
      str_detect(ofns_desc, "DRIVE")~"theft_property",
      TRUE~"other"
    ),
    crime_type=factor(crime_type)
  )

df1 %>% 
  select(crime_type) %>% 
  n_distinct()

```

Three Seems to be more manageable. Now that I have crime data, I can examine any seasonal patterns that might yield insights. For that l will look at scatterplot of the monthly assaults as a proxy measure for violent crimes.

```{r}

df1 %>% 
  filter(crime_type == "violent") %>% 
  group_by(year_mon) %>% 
  summarize(count = n()) %>%
  ungroup() %>% 
  ggplot(aes(year_mon,count))+
    geom_point()+
    geom_line()
  

```

There appears to be a seasonal spike in violent crimes during the summer months. It does appear that there is an overall lack of crime reported in 2020 probably due to COVID. With this seasonality in mind, I plan to add NOAA weather data to the overall data set to see how weather might affect the overall daily violent crimes. From previous work with forecasting grocery demand, I know that holidays influence behaviors. I will add a list of national holidays to help tease out any effects that holidays might have on crime.

```{r}
# Weather data obtained from NOAA
df_weather <- read_csv("https://www.ncei.noaa.gov/orders/cdo/2353296.csv") %>% 
  janitor::clean_names() %>% 
  select(date,awnd,prcp,snow,snwd,tmax,tmin,wsf2,wt01,wt02,wt03,wt04,wt06,wt08) %>% 
  replace_na(list(wt01=0,wt02=0,wt03=0,wt04=0,wt06=0,wt08=0))
# Holidays
df_holiday <- read_csv("usholidays.csv") %>% 
  janitor::clean_names()  %>% 
  mutate(date = lubridate::mdy(date))

```


Now lets add these features to our data set.

```{r}
df1 <-df1 %>% 
  inner_join(df_weather,by = c("occur_date"="date")) %>% 
  left_join(df_holiday, by = c("occur_date" = "date")) %>% 
  mutate(holiday = ifelse(is.na(holiday),0,1))
glimpse(df1)
```
To do a bit of a sanity check, I want to see if rain has a visual effect on the number of murders. 

```{r}
boro_site <- "https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=GeoJSON" #CAA internet blocked me from downloading this
# load boros
nyboros <- geojsonio::geojson_read("json/Borough Boundaries.geojson", what = "sp") 
#prepare color mapping
nyboros$boro_name <- factor(nyboros$boro_name)
factpal <- colorFactor("Set1", nyboros$boro_name)
# build murders in the rain map
leaflet() %>% 
  addPolygons(data = nyboros, weight = 2, fillColor = ~factpal(boro_name), group = "Boros") %>% 
  setView(-74,40.7,zoom=10) %>% 
  addTiles(group = "default") %>% 
  addMarkers(data = df1 %>% filter(statistical_murder_flag == TRUE & prcp>0.1),~longitude, ~latitude,popup = ~as.character(boro), label = ~as.character(ofns_desc), group = "Shooting Murders in the Rain") %>% 
  addMarkers(data = df1 %>% filter(statistical_murder_flag == TRUE & prcp==0),~longitude, ~latitude,popup = ~as.character(boro), label = ~as.character(ofns_desc), group = "Shooting Murders in the Clear") %>% 
  addLayersControl(
    baseGroups = c("default"),
    overlayGroups = c("Boros", "Shooting Murders in the Rain", "Shooting Murders in the Clear"),
    options = layersControlOptions(collapsed = FALSE))

```

The Map above demonstrates why I think weather is a factor. If it’s a rainy day there are way less shooting murders. I think I should model crime. I plan to focus on building a predictive model across each Boro to determine how many violent crimes, theft/property crimes and other crimes the NYPD should expect on a given month and date of week. The parameters to control will include weather and holidays. 

```{r}
df2 <-  df1 %>% 
  select(occur_date,boro,month,awnd,prcp,snow,tmax,tmin,wsf2,wt01,wt02,wt03,wt04,wt06,wt08,holiday,crime_type) %>% 
  mutate(
    prcp = ifelse(prcp >0.25, 1,0),
    snow = ifelse(snow >0.25, 1,0),
    awnd = ifelse(awnd>mean(awnd,na.rm = T),1,0), # proxy for windy days
    weekday = lubridate::wday(occur_date,label = F, abbr = F)
  ) %>% 
  group_by(boro,occur_date, crime_type) %>% 
  mutate(value = n()) %>% 
  distinct() %>% 
  ungroup() %>% 
  select(-occur_date) %>% 
  na.omit()

glimpse(df2)
```

Since we are attempting to predict 3 outputs across 5 boros I plan to take a simple approach using a nested linear model.  

```{r}
library(tidymodels)
lm_model <- df2 %>% 
  group_by(boro,crime_type) %>% 
  nest() %>% 
  mutate(model= map(data,  ~lm(value~.,data=.x)),
         predicted = map2(model,data,predict))
saveRDS(lm_model,"model.RDS") # save model for later use 

eval <-  lm_model %>% 
  mutate(glance = map(model,glance)) %>% 
  unnest(glance)
  
eval
```


The models are not great overall, but it is easy to tweak and refine the assumptions to build a more predictive model. In this example, I'm just using a linear model to use as to build a minimum viable product that the client can use in the future. Now that I have a model, I'll design a method to take user input and make a daily prediction. The NYPD could better allocate their scarce resources to the correct Boros where they should expect higher crime rates on a given day of a month.I'll use a shiny app for this. 

```{r}
test <- df2 %>% 
  group_by(boro,crime_type) %>% 
  sample_n(1) %>% 
  select(-value) %>% 
  nest()

df_test <-test %>% select(boro,crime_type) %>% ungroup()
#write_csv(df_test, "pred_df.csv")
preds <- df_test %>% 
  mutate(pred = map2(lm_model$model,test$data,predict)) %>% 
  unnest(pred)
preds
```



